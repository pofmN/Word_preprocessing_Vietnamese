# ü™Ñ Word Regular Expression <img src="https://i0.wp.com/www.printmag.com/wp-content/uploads/2021/02/4cbe8d_f1ed2800a49649848102c68fc5a66e53mv2.gif?fit=476%2C280&ssl=1" width="100" height="45"/>

---
## Kh√°i ni·ªám, m·ª•c ti√™u
>RegEx - hay c√≤n ƒë∆∞·ª£c bi·∫øt Regular Expression(Bi·ªÉu th·ª©c ch√≠nh quy) - l√† c√°c m·∫´u(pattern) thay v√¨ c√°c chu·ªói c·ª• th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√¨m/thay th·∫ø(Find/Replace).

>M·ª•c ti√™u c·ªßa vi·ªác RegEx l√† t√°ch t·ª´ng t·ª´ theo pattern ƒë√£ ƒë∆∞a ra. ƒêi·ªÅu n√†y gi√∫p ta x·ª≠ l√Ω Ti·∫øng Vi·ªát v√† s·ª≠ d·ª•ng ng√¥n ng·ªØ n√†y d·ªÖ d√†ng v√† hi·ªáu qu·∫£ h∆°n.

>Tham kh·∫£o t·ª´ code RegEx c·ªßa [Under The Sea](https://github.com/undertheseanlp/underthesea/blob/main/underthesea/pipeline/word_tokenize/regex_tokenize.py) kho·∫£ng 50 pattern v√† ph√°t tri·ªÉn th√™m kho·∫£ng 30 pattern.
---
## C√°c ph·∫ßn ƒë∆∞·ª£c th√™m v√† ch·ªânh s·ª≠a
·∫∂cccc

---
##  M·ª•c l·ª•c üìë

[1. Li·ªát k√™ c√°c k√Ω t·ª± v√† s·ªë](#1-li·ªát-k√™-c√°c-k√Ω-t·ª±-v√†-s·ªë-)

[2. RegEx c√≥ m·ª©c ƒë·ªô ∆∞u ti√™n 1](#2-regex-c√≥-m·ª©c-ƒë·ªô-∆∞u-ti√™n-1%EF%B8%8F‚É£)

[3. RegEx c√≥ m·ª©c ƒë·ªô ∆∞u ti√™n 2](#3-regex-c√≥-m·ª©c-ƒë·ªô-∆∞u-ti√™n-2%EF%B8%8F‚É£)

-    [a. Pattern v·ªÅ URL](#a-pattern-v·ªÅ-url-)
   
-    [b. Pattern v·ªÅ email](#b-pattern-v·ªÅ-email-%EF%B8%8F)
  
-    [c. Pattern v·ªÅ s·ªë ƒëi·ªán tho·∫°i](#c-pattern-v·ªÅ-s·ªë-ƒëi·ªán-tho·∫°i-%EF%B8%8F)
  
-    [d. Pattern v·ªÅ ng√†y th√°ng](#d-pattern-v·ªÅ-ng√†y-th√°ng-)
  
-    [e. Pattern v·ªÅ danh t·ª´ ch·ªâ ƒë∆°n v·ªã ƒëi k√®m](#e-pattern-v·ªÅ-danh-t·ª´-ch·ªâ-ƒë∆°n-v·ªã-ƒëi-k√®m-)
  
-    [f. Pattern v·ªÅ s·ªë](#f-pattern-v·ªÅ-s·ªë-)
  
-    [g. Pattern v·ªÅ bi·ªÉu c·∫£m](#g-pattern-v·ªÅ-bi·ªÉu-c·∫£m-)
  
-    [h. Pattern v·ªÅ d·∫•u](#h-pattern-v·ªÅ-d·∫•u-)
    
[4. RegEx c√≥ m·ª©c ƒë·ªô ∆∞u ti√™n 3](#4-regex-c√≥-m·ª©c-ƒë·ªô-∆∞u-ti√™n-3%EF%B8%8F‚É£)

[5. Th√™m pattern](#5-th√™m-pattern-)

[6. Tr√≠ch xu·∫•t match](#6-tr√≠ch-xu·∫•t-match-%EF%B8%8F)

[7. H√†m tokenize](#7-h√†m-tokenize)

---
## 1. Li·ªát k√™ c√°c k√Ω t·ª± v√† s·ªë üî§üî¢
`CHARACTER`: ch·ªØ hoa v√† th∆∞·ªùng c·ªßa k√Ω t·ª± c√≥ d·∫•u(√°, ·∫Ø, ·∫•, ...)
```python
VIETNAMESE_CHARACTER_UPPER = "[" + "|".join([
    "ABCDEFGHIJKLMNOPQRSTUVXYZ",
    "√Ä√Å·∫¢√É·∫†",
    "ƒÇ·∫∞·∫Æ·∫≤·∫¥·∫∂",
    "√Ç·∫¶·∫§·∫®·∫™·∫¨",
    "ƒê",
    "√à√â·∫∫·∫º·∫∏",
    "√ä·ªÄ·∫æ·ªÇ·ªÑ·ªÜ",
    "√å√ç·ªàƒ®·ªä",
    "√í√ì·ªé√ï·ªå",
    "√î·ªí·ªê·ªî·ªñ·ªò",
    "∆†·ªú·ªö·ªû·ª†·ª¢",
    "√ô√ö·ª¶≈®·ª§",
    "∆Ø·ª™·ª®·ª¨·ªÆ·ª∞",
    "·ª≤√ù·ª∂·ª∏·ª¥"
]) + "]"
VIETNAMESE_CHARACTER_LOWER = VIETNAMESE_CHARACTER_UPPER.lower()
CHARAC = "[" + VIETNAMESE_CHARACTER_UPPER[1:-1] + VIETNAMESE_CHARACTER_LOWER[1:-1] + "]"
```
`NUMBER`: ch·ªØ hoa v√† th∆∞·ªùng c·ªßa s·ªë ·ªü d·∫°ng ch·ªØ(m·ªôt, m·ªët, hai, ...)
```python
VIETNAMESE_NUMBER_UPPER = "[" + "|".join([
    "LINH", "Linh",
    "L·∫∫", "L·∫ª",
    "PH·∫®Y", "Ph·∫©y"
    "PH·∫¶N", "Ph·∫ßn"
    "KH√îNG", "Kh√¥ng",
    "M·ªòT", "M·ªôt",
    "M·ªêT", "M·ªët",
    "HAI", "Hai",
    "BA", "Ba",
    "B·ªêN", "B·ªën",
    "T∆Ø", "T∆∞",
    "NƒÇM", "NƒÉm",
    "LƒÇM", "LƒÉm",
    "R∆Ø·ª†I", "R∆∞·ª°i",
    "S√ÅU", "S√°u",
    "B·∫¢Y", "B·∫£y",
    "T√ÅM", "T√°m",
    "CH√çN", "Ch√≠n",
    "M∆Ø·ªúI", "M∆∞·ªùi",
    "M∆Ø∆†I", "M∆Ø∆†I",
    "CH·ª§C", "Ch·ª•c",
    "TRƒÇM", "TrƒÉm",
    "NGH√åN", "Ngh√¨n",
    "NG√ÄN", "Ng√†n",
    "TRI·ªÜU", "Tri·ªáu",
    "T·ª∂", "T·ª∑",
    "T·ªà", "T·ªâ"
]) + "]"
VIETNAMESE_NUMBER_LOWER = VIETNAMESE_NUMBER_UPPER.lower()

NUMBER = "[" + VIETNAMESE_NUMBER_UPPER[1:-1] + VIETNAMESE_NUMBER_LOWER[1:-1] + "]"
```
---
## 2. RegEx c√≥ m·ª©c ƒë·ªô ∆∞u ti√™n 1Ô∏è‚É£
### Pattern v·ªÅ d·∫•u v√† vi·∫øt t·∫Øt üóíÔ∏è
`specials`: pattern v·ªÅ tr∆∞·ªùng h·ª£p ƒë·∫∑t bi·ªát c·ªßa d·∫•u (`Ex`: =>, ->, ¬∞C, ...)
```python
specials = [
    r"\=+\>+", # e.g ==>>
    r"->", # e.g -->>
    r"\.{2,}", # e.g ...
    r"-{2,}", # e.g ---
    r"\>+\>+", # e.g >>>
    r"[\d,./]+x+(?:[,./x\d])+", # e.g 3x4x...
    r"v\.v\.\.\.", # e.g v.v....
    r"v\.v\.", 
    r"v\.v",
    r"¬∞[CF]" # e.g ¬∞C
]
specials = "(?P<special>(" + "|".join(specials) + "))"
```
`abbreviations`: pattern v·ªÅ t·ª´ vi·∫øt t·∫Øt(`Ex`: TP.H·ªì Ch√≠ Minh, PGS.TS, H'M√¥ng, ...)
```python
abbreviations = [
    r"[A-Zƒê]+&[A-Zƒê]+",  # e.g. H&M
    r"\d+[A-Za-z]+(\w?)+-\d+.\d+", # e.g. 43H-053.09 | 43H1-053.09
    r"[A-Za-z]+-+[A-Za-z]+([A-Za-z-]+)?", # e.g 1GZ-FE, MC-Asenal-MU
    r"[\d.,]+\%|[\d.,]+\‚Ä∞|[\d.,]+\‚Ä±", #e.g 100% | 100‚Ä∞ | 100‚Ä±
    r"Tp\.",
    r"Mr\.", r"Mrs\.", r"Ms\.",
    r"Dr\.", r"ThS\.", r"Th.S", r"Th.s", r"TS\.", r"Ts\.", r"T.S",
    r"[A-Za-z]+\.+[A-Za-z]+",  # dot at middle of word e.g PGS.TS
    f"{VIETNAMESE_CHARACTER_UPPER}+(?:\.{CHARAC}+)+\.?",
    f"{CHARAC}+['‚Äô]{CHARAC}+",  #  e.g. H'M√¥ng, x√£ N‚ÄôTh√¥n H·∫°
    r"[A-Zƒê]+\.(.?!;$)"  # dot at the end of word
]
abbreviations = "(?P<abbr>(" + "|".join(abbreviations) + "))"
```
---
## 3. RegEx c√≥ m·ª©c ƒë·ªô ∆∞u ti√™n 2Ô∏è‚É£
### a. Pattern v·ªÅ URL üî£
`URL`: pattern v·ªÅ URL(`Ex`: github.com/ketdoannguyen/AI_EmbeddingVietnameseNLP)

>Code c√≥ tham kh·∫£o t·ª´ [NLTK](https://www.nltk.org/_modules/nltk/tokenize/casual.html)

```python
url = r"""             # Capture 1: entire matched URL
  (?:
  (ftp|http)s?:               # URL protocol and colon
    (?:
      /{1,3}            # 1-3 slashes
      |                 #   or
      [a-z0-9%]         # Single letter or digit or '%'
                        # (Trying not to match e.g. "URI::Escape")
    )
    |                   #   or
                        # looks like domain name followed by a slash:
    [a-z0-9.\-]+[.]
    (?:[a-z]{2,13})
    /
  )
  (?:                                  # One or more:
    [^\s()<>{}\[\]]+                   # Run of non-space, non-()<>{}[]
    |                                  #   or
    \([^\s()]*?\([^\s()]+\)[^\s()]*?\) # balanced parens, one level deep: (...(...)...)
    |
    \([^\s]+?\)                        # balanced parens, non-recursive: (...)
  )+
  (?:                                  # End with:
    \([^\s()]*?\([^\s()]+\)[^\s()]*?\) # balanced parens, one level deep: (...(...)...)
    |
    \([^\s]+?\)                        # balanced parens, non-recursive: (...)
    |                                  #   or
    [^\s`!()\[\]{};:'".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô]     # not a space or one of these punct chars
  )
  |                        # OR, the following to match naked domains:
  (?:
    (?<!@)                 # not preceded by a @, avoid matching foo@_gmail.com_
    [a-z0-9]+
    (?:[.\-][a-z0-9]+)*
    [.]
    (?:[a-z]{2,13})
    \b
    /?
    (?!@)                  # not succeeded by a @,
                           # avoid matching "foo.na" in "foo.na@example.com"
  )
"""
url = "(?P<url>" + url + ")"
```
### b. Pattern v·ªÅ email ‚úâÔ∏è
`email`: pattern v·ªÅ email(`Ex`: nhokmant2003@gmail.com)
```python
email = r""" ([-!#-'*+/-9=?A-Z^-~]+(\.[-!#-'*+/-9=?A-Z^-~]+)*|
            \"([]!#-[^-~ \t]|(\\[\t -~]))+\")@([-!#-'*+/-9=?A-Z^-~]+
            (\.[-!#-'*+/-9=?A-Z^-~]+)*|\[[\t -Z^-~]*])
        """
email = "(?P<email>" + email + ")"
```
### c. Pattern v·ªÅ s·ªë ƒëi·ªán tho·∫°i ‚òéÔ∏è
`phone`: pattern v·ªÅ phone(`Ex`: +84xxxxxxxxx, 0084xxxxxxxxx, 09-xxxx-xxxx, ...)
```python
phone = [
    r"\d{2,}-\d{3,}-\d{3,}",  # e.g. 03-5730-2357
    r"(?:\+84)+(\s?)+[\d-]+", # e.g +84xxx-xxx-xxx
    r"(?:0084)+(\s?)+[\d-]+", # e.g 0084xxx-xxx-xxx
    r"(?:00\s84)+(\s?)+[\d-]+" # e.g 00 84xxx-xxx-xxx
    # very careful, it's easy to conflict with datetime
]
phone = "(?P<phone>(" + "|".join(phone) + "))"
```
### d. Pattern v·ªÅ ng√†y th√°ng üìÖ
`datetime`: pattern v·ªÅ datetime(`Ex`: 11/07/2023, 11:35:10, 11H35P10', ...)
```python
datetime = [
    # date
    r"\d{1,2}\/\d{1,2}\/\d+",  # e.g. 02/05/2014
    r"\d{1,2}\/\d{1,4}",  # e.g. 02/2014
    # [WIP] conflict with number 1/2 (a half)
    r"\d{1,2}-\d{1,2}-\d+",  # e.g. 02-03-2014
    r"\d{1,2}-\d{1,4}",  # e.g. 08-2014
    # [WIP] conflict with range 5-10 (from 5 to 10)
    r"\d{1,2}\.\d{1,2}\.\d+",  # e.g. 20.08.2014
    r"\d{4}\/\d{1,2}\/\d{1,2}",  # e.g. 2014/08/20
    r"\d{2}:\d{2}:\d{2}|\d{2}:\d{2}",  # e.g. 10:20:50 | 10:20
    r"\d+[Hh]+\d+[Pp]+\d+[Ss']+|\d+[Hh]+\d+[Pp]+|\d+[Hh]+\d+"
    # e.g 14h20p30s, 14H20P30S | 14h20p, 14H20P | 14h20,14H20
]
datetime = "(?P<datetime>(" + "|".join(datetime) + "))"
```

### e. Pattern v·ªÅ danh t·ª´ ch·ªâ ƒë∆°n v·ªã ƒëi k√®m üí≤
`units`: pattern v·ªÅ units(`Ex`: l·∫ßn/ng√†y, 1M5, ...)
```python
units = [
    f"(?<={NUMBER}\s)({CHARAC}+/+{CHARAC}+)+",  # e.g 2 tri·ªáu l·∫ßn/ng√†y
    f"(?<=[.,\d]\s)({CHARAC}+/+{CHARAC}+)+",  # e.g 2 l·∫ßn/ng√†y
    f"[.,\d]+{CHARAC}+/+{CHARAC}+",  # e.g 4l·∫ßn/ng√†y
    r"([.,\d]?)+[A-Za-z/]+[/\d]+([A-Za-z/]|[/\d]?)+",  # e.g A/F/300/200
    r"([.,\d])+[A-Za-z]+([/\d]?)+(\"|\')?"  # e.g 1.05Jx19" | 1M5
]
units = "(?P<acro>(" + "|".join(units) + "))"
```
### f. Pattern v·ªÅ s·ªë üî¢
`number`: pattern v·ªÅ number(`Ex`: 4.123,2 | 60.231.222 | 23,333,122 |...)
```python
number = [
    r"\d+(?:\.\d+)+,\d+",  # e.g. 4.123,2,..
    r"\d+(?:\.\d+)+",  # e.g. 60.542.000,..
    r"\d+(?:,\d+)+",  # e.g. 100,000,000,...
    r"\d+(?:\/\d+)+", # e.g 255/255/3/...
    r"\d+(?:\-\d+)+", # e.g 055-022-0000-...
    r"\d+(?:[\.,_]\d+)?"  # 123
]
number = "(?P<number>(" + "|".join(number) + "))"  
```
### g. Pattern v·ªÅ bi·ªÉu c·∫£m üóø
`emoji`: pattern v·ªÅ emoji(`Ex`: :), :P, :D, <3, ...)
>Code c√≥ tham kh·∫£o t·ª´ [NLTK](https://www.nltk.org/_modules/nltk/tokenize/casual.html)
```python
emoji = [
    r":+\)+",
    r"=+\)+",
    r"√∑+\)+",
    r":D+(?=\s)",
    r":D+(?=$)",
    r"""
    (?:
      [<>]?
      [:;=8]                     # eyes
      [\-o\*\']?                 # optional nose
      [\)\]\(\[dDpP/\:\}\{@\|\\] # mouth
      |
      [\)\]\(\[dDpP/\:\}\{@\|\\] # mouth
      [\-o\*\']?                 # optional nose
      [:;=83v]                     # eyes
      [<>]?
      |
      </?3                       # heart
    )"""
]
```
### h. Pattern v·ªÅ d·∫•u üî£
`punct`: pattern v·ªÅ punct(`Ex`: . , ( ) )
```python
punct = [
    r"\.",
    r"\,",
    r"\(",
    r"\)",
    r" ∫"
]
punct = "(?P<punct>(" + "|".join(punct) + "))"
```
---
## 4. RegEx c√≥ m·ª©c ƒë·ªô ∆∞u ti√™n 3Ô∏è‚É£
### Pattern v·ªÅ t·ª´, g·∫°ch n·ªëi t·ª´, d·∫•u trong to√°n v√† non-word  üî§‚ûñ‚ôæÔ∏è
`word`: pattern v·ªÅ word(`Ex`: a, b, c, ...)
```python
word = r"(?P<word>\w+)"
```
`word_hyphen`: pattern v·ªÅ word hyphen(`Ex`: Anh-Em, ...)
```python
word_hyphen = [
    r"(?<=\b)\w+\-[\w+-]*\w+",  # before word_hyphen must be word boundary
    # case to notice: 1.600m-2.000m
]
word_hyphen = "(?P<word_hyphen>(" + "|".join(word_hyphen) + "))"
```
`symbol`: pattern v·ªÅ symbol(`Ex`: +, -, x, √∑, ...)
```python
symbol = [
    r"\+",
    r"√ó",
    r"-",
    r"√∑",
    r":+",
    r"%",
    r"\$",
    r">=",
    r"<=",
    r"\=+",
    r">",
    r"<",
    r"\^",
    r"_",
    r":+"
]
symbol = "(?P<sym>(" + "|".join(symbol) + "))"
```
`non_word`: pattern v·ªÅ non word(`Ex`: { } | ...)
```python
non_word = r"(?P<non_word>[^\w\s])"
```
---
## 5. Th√™m pattern ‚ûï
```python
# Caution: order is very important for regex
regex_patterns = [
    specials,  # Priority 1
    abbreviations,
    url,  # Priority 2
    email,
    phone,
    datetime,  # datetime must be before
    units,
    number,
    emoji,
    punct,
    # Priority 3
    word_hyphen,
    word,
    symbol,
    non_word  # non_word must be last
]
recompile_regex_patterns = False
regex_patterns_combine = r"(" + "|".join(regex_patterns) + ")"
if sys.version_info < (3, 0):
    regex_patterns_combine = regex_patterns_combine.decode('utf-8')
patterns = re.compile(regex_patterns_combine, re.VERBOSE | re.UNICODE)

# regex pattern to match extacted word "Vi·ªán nghi√™n c·ª©u" or "chien luoc"
# and not match to other multi tokens word, such as "quoc gia"
pattern = re.compile(r"(\w+)(?:\s+)(\w+)", re.UNICODE)
```
- `regex_patterns` ƒë∆∞a patterns ƒë√£ so·∫°n v√†o m·ªôt pattern chung
- `regex_patterns_combine` combine c√°c patterns
- `patterns` compile cac patterns
---
## 6. Tr√≠ch xu·∫•t match ‚û°Ô∏è
```python
def extract_match(m):
    for k, v in m.groupdict().items():
        if v is not None:
            return v, k
```
- `extract_match` nh√≥m c√°c t·ª´ ƒë√£ ƒë∆∞·ª£c RegEx b·∫±ng `groupdict`
---
## 7. H√†m tokenize
```python
def tokenize(text, format=None, tag=False, use_character_normalize=True, use_token_normalize=True, fixed_words=[]):
    """
    tokenize text for word segmentation

    Args:
        use_token_normalize: use token normalize or not
        use_character_normalize: use character normalize or not
        tag: return token with tag or not
        format: format of result, default is None
    """
    global recompile_regex_patterns
    global patterns
    if len(fixed_words) > 0:
        compiled_fixed_words = [re.sub(' ', '\ ', fixed_word) for fixed_word in fixed_words]
        fixed_words_pattern = "(?P<fixed_words>" + "|".join(compiled_fixed_words) + ")"
        merged_regex_patterns = [fixed_words_pattern] + regex_patterns
        regex_patterns_combine = r"(" + "|".join(merged_regex_patterns) + ")"
        patterns = re.compile(regex_patterns_combine, re.VERBOSE | re.UNICODE)
        recompile_regex_patterns = True
    matches = [m for m in re.finditer(patterns, text)]
    tokens = [extract_match(m) for m in matches]

    if tag:
        return tokens

    tokens = [token[0] for token in tokens]

    if format == "text":
        return " ".join(tokens)

    return tokens
```
- H√†m `tokenize` c√≥ ƒë·∫ßu v√†o l√† m·ªôt text, `format` l√† text
- N·∫øu text c√≥ vƒÉn b·∫£n h√†m s·∫Ω t√°ch c√°c t·ª´ theo pattern v√† nh√≥m l·∫°i b·∫±ng `extract_match`
---
